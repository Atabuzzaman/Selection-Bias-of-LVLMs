{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter \n",
    "\n",
    "# for qwen2.5-vl\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d48063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing bird subfolders\n",
    "images_folder = '/CUB_200_2011/images'\n",
    "\n",
    "# Dictionary to store bird names and their corresponding image paths\n",
    "bird_images = {}\n",
    "\n",
    "# Iterate over each subfolder in the images folder\n",
    "for folder in os.listdir(images_folder):\n",
    "    bird_name = folder.split(\".\")[-1]  # Extract bird name from folder name\n",
    "    folder_path = os.path.join(images_folder, folder)  # Path to the bird's folder\n",
    "    \n",
    "    # Initialize an empty list to store image paths for the current bird\n",
    "    image_paths = []\n",
    "    \n",
    "    # Iterate over the image files in the bird's folder\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_file)  # Full path to the image file\n",
    "        image_paths.append(image_path)  # Store the image path\n",
    "    \n",
    "    # Store the list of image paths in the dictionary under the bird's name\n",
    "    bird_images[bird_name] = image_paths\n",
    "\n",
    "# Now bird_images contains a dictionary where the keys are bird names and the values are lists of image paths\n",
    "print(len(bird_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1015dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_images['Black_footed_Albatross'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11b06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_names = bird_images.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For with class name setting: \n",
    "# with open(\"new_cub_with_class_descriptions.json\", \"r\") as file:\n",
    "#     json_data = json.load(file)\n",
    "# print(len(json_data))\n",
    "\n",
    "# For without class name setting: \n",
    "with open(\"new_cub_class_descriptions.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "print(len(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db43b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if the json file contain the medium and hard categories\n",
    "medium_data = []\n",
    "hard_data = []\n",
    "for data in json_data:\n",
    "    if data['difficulty'] == \"Medium\":\n",
    "        medium_data.append(data)\n",
    "    else:\n",
    "        hard_data.append(data)\n",
    "print(len(medium_data))\n",
    "print(len(hard_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80cfa4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(image_path, query):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image_path,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        # videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128) \n",
    "    # print(generated_ids)\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters for distribution\n",
    "true_distribution = Counter()\n",
    "predicted_distribution = Counter()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in tqdm(enumerate(hard_data)): # for easy part json_data, for medium_data, for hard_data \n",
    "    mcq_id = item['mcq_id']\n",
    "    question = item['question']\n",
    "    options = item['options']\n",
    "    correct_answer = item['correct_answer']\n",
    "\n",
    "    if mcq_id not in bird_images or not bird_images[mcq_id]:\n",
    "        print(f\"No image for {mcq_id}\") \n",
    "        continue\n",
    "\n",
    "    image_paths = bird_images[mcq_id][:5]\n",
    "\n",
    "    # Format the prompt\n",
    "    formatted_prompt = f\"{question}\\n\"\n",
    "    for k in ['A', 'B', 'C', 'D']:  # ['D', 'C', 'B', 'A'] for position bias checking ['A', 'B', 'C', 'D']\n",
    "        formatted_prompt += f\"{k}. {options[k]}\\n\"\n",
    "\n",
    "    # Final prompt\n",
    "    prompt = f\"\"\" Your answer or response must ONLY be a single index ('A', 'B', 'C', 'D'). Do not response with any other text. \n",
    "\n",
    "    {formatted_prompt}\n",
    "\n",
    "    Answer: ('A', 'B', 'C', 'D')\"\"\"\n",
    "\n",
    "    # Run the model\n",
    "    for image_path in image_paths:\n",
    "        model_output = get_answer(image_path, prompt)\n",
    "        # print(\"Model Output: \", model_output)\n",
    "\n",
    "        # Extract predicted answer (basic string search, can refine)\n",
    "        predicted_answer = None\n",
    "        for option in ['A', 'B', 'C', 'D']:\n",
    "            if f\"{option}\" in model_output or f\"{option}.\" in model_output:\n",
    "                predicted_answer = option\n",
    "\n",
    "        # Update counters\n",
    "        true_distribution[correct_answer] += 1\n",
    "        if predicted_answer:\n",
    "            predicted_distribution[predicted_answer] += 1\n",
    "        \n",
    "        results.append({\n",
    "            'mcq_id': mcq_id,\n",
    "            'image_path': image_path,\n",
    "            'prompt': prompt,\n",
    "            'model_output': model_output,\n",
    "            'predicted_answer': predicted_answer,\n",
    "            'correct_answer': correct_answer,\n",
    "            'is_correct': predicted_answer == correct_answer\n",
    "        })\n",
    "\n",
    "# Accuracy summary \n",
    "correct = sum(r['is_correct'] for r in results if r['predicted_answer'] is not None)\n",
    "total = len(results)\n",
    "print(f\"Accuracy: {correct}/{total} = {correct / total:.2%}\") \n",
    "\n",
    "# Print distributions\n",
    "print(\"True Option Distribution:\", dict(true_distribution))\n",
    "print(\"Predicted Option Distribution:\", dict(predicted_distribution)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c4f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
